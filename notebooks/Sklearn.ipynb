{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone -b master https://github.com/charles9n/bert-sklearn\n",
    "#!cd bert-sklearn; pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import statistics as stats\n",
    "\n",
    "from bert_sklearn import BertClassifier\n",
    "from bert_sklearn import BertRegressor\n",
    "from bert_sklearn import BertTokenClassifier\n",
    "from bert_sklearn import load_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/22/2020 12:15:00 - INFO - transformers.file_utils -   PyTorch version 1.4.0 available.\n",
      "04/22/2020 12:15:01 - INFO - transformers.file_utils -   TensorFlow version 2.0.0 available.\n",
      "04/22/2020 12:15:02 - INFO - numexpr.utils -   NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import vectorize\n",
    "import helpers\n",
    "import transformers\n",
    "from utils import *\n",
    "from loss.loss import *\n",
    "\n",
    "from bert_sklearn_transformer import BertTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_pickle(\"../data/full_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB = None\n",
    "MAX_SEQ_LENGTH = 5000\n",
    "full_df['TEXT_PROCESSED'] = vectorize.clean_notes(full_df, 'TEXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['ICD9_GRP_LIST'] = full_df.ICD9_GRP.apply(lambda x: re.split(\" +\", x.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of splitting the data\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "split = np.random.choice(\n",
    "    [\"train\", \"val\", \"test\"],\n",
    "    size=full_df.shape[0],\n",
    "    p=[.7, .15, .15]\n",
    ")\n",
    "full_df[\"split\"] = split\n",
    "\n",
    "sample_df = full_df.sample(frac=0.3)\n",
    "\n",
    "\n",
    "X_train = sample_df[sample_df[\"split\"] == \"train\"]['TEXT_PROCESSED']\n",
    "y_train = mlb.fit_transform(sample_df[sample_df[\"split\"] == \"train\"]['ICD9_GRP_LIST'])\n",
    "\n",
    "X_test = sample_df[sample_df[\"split\"] == \"test\"]['TEXT_PROCESSED']\n",
    "y_test = mlb.transform(sample_df[sample_df[\"split\"] == \"test\"]['ICD9_GRP_LIST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append((\"LogisticRegression\",LogisticRegression()))\n",
    "models.append((\"SVC\",SVC()))\n",
    "models.append((\"LinearSVC\",LinearSVC()))\n",
    "models.append((\"KNeighbors\",KNeighborsClassifier()))\n",
    "models.append((\"DecisionTree\",DecisionTreeClassifier()))\n",
    "models.append((\"RandomForest\",RandomForestClassifier()))\n",
    "rf2 = RandomForestClassifier(n_estimators=100, criterion='gini',\n",
    "                                max_depth=10, random_state=0, max_features=None)\n",
    "models.append((\"RandomForest2\",rf2))\n",
    "models.append((\"MLPClassifier\",MLPClassifier(solver='lbfgs', random_state=0)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name,model in models:\n",
    "    result = cross_val_score(model, X_train, y_train,  cv=3)\n",
    "    names.append(name)\n",
    "    results.append(result)\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(names[i],results[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, multilabel_confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#classifier = SGDClassifier()\n",
    "#classifier = XGBClassifier(n_jobs=-1, max_depth=4)\n",
    "classifier = RandomForestClassifier()\n",
    "model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(2,2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(classifier)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-d768f88d541e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;34m\"not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[0;32m--> 239\u001b[0;31m             for i, column in enumerate(columns))\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[0;34m(estimator, X, y, classes)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vectorizer__ngram_range': [(1, 1), (1, 2),(2,2)],\n",
    "               'tfidf__use_idf': (True, False)}\n",
    "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X_train, y_train)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2355,    0],\n",
       "        [   0,    0]],\n",
       "\n",
       "       [[1674,  274],\n",
       "        [  78,  329]],\n",
       "\n",
       "       [[1972,  204],\n",
       "        [  10,  169]],\n",
       "\n",
       "       [[ 390,   96],\n",
       "        [ 406, 1463]],\n",
       "\n",
       "       [[ 741,  269],\n",
       "        [ 402,  943]],\n",
       "\n",
       "       [[1561,  391],\n",
       "        [  99,  304]],\n",
       "\n",
       "       [[ 269,   23],\n",
       "        [ 240, 1823]],\n",
       "\n",
       "       [[1094,  298],\n",
       "        [ 170,  793]],\n",
       "\n",
       "       [[1328,  375],\n",
       "        [ 113,  539]],\n",
       "\n",
       "       [[1243,  290],\n",
       "        [ 192,  630]],\n",
       "\n",
       "       [[2350,    5],\n",
       "        [   0,    0]],\n",
       "\n",
       "       [[2112,  230],\n",
       "        [   0,   13]],\n",
       "\n",
       "       [[1884,  421],\n",
       "        [  11,   39]],\n",
       "\n",
       "       [[2111,   64],\n",
       "        [   0,  180]],\n",
       "\n",
       "       [[1512,  470],\n",
       "        [ 134,  239]],\n",
       "\n",
       "       [[2169,  186],\n",
       "        [   0,    0]],\n",
       "\n",
       "       [[2285,   70],\n",
       "        [   0,    0]],\n",
       "\n",
       "       [[1201,  356],\n",
       "        [ 190,  608]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation on test data\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "multilabel_confusion_matrix(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.81      0.55      0.65       603\n",
      "           2       0.94      0.45      0.61       373\n",
      "           3       0.78      0.94      0.85      1559\n",
      "           4       0.70      0.78      0.74      1212\n",
      "           5       0.75      0.44      0.55       695\n",
      "           6       0.88      0.99      0.93      1846\n",
      "           7       0.82      0.73      0.77      1091\n",
      "           8       0.83      0.59      0.69       914\n",
      "           9       0.77      0.68      0.72       920\n",
      "          10       0.00      0.00      0.00         5\n",
      "          11       1.00      0.05      0.10       243\n",
      "          12       0.78      0.08      0.15       460\n",
      "          13       1.00      0.74      0.85       244\n",
      "          14       0.64      0.34      0.44       709\n",
      "          15       0.00      0.00      0.00       186\n",
      "          16       0.00      0.00      0.00        70\n",
      "          17       0.76      0.63      0.69       964\n",
      "\n",
      "   micro avg       0.80      0.67      0.73     12094\n",
      "   macro avg       0.64      0.44      0.49     12094\n",
      "weighted avg       0.78      0.67      0.69     12094\n",
      " samples avg       0.82      0.68      0.72     12094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = full_df.TEXT_PROCESSED.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [d.split() for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/22/2020 13:07:32 - WARNING - smart_open.transport -   unable to import 'smart_open.gcs', disabling that module\n",
      "04/22/2020 13:07:32 - WARNING - gensim.models.base_any2vec -   consider setting layer size to a multiple of 4 for greater performance\n",
      "04/22/2020 13:07:32 - INFO - gensim.models.word2vec -   collecting all words and their counts\n",
      "04/22/2020 13:07:32 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "04/22/2020 13:07:35 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #10000, processed 16230158 words, keeping 60607 word types\n",
      "04/22/2020 13:07:38 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #20000, processed 32505504 words, keeping 85084 word types\n",
      "04/22/2020 13:07:42 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #30000, processed 48845407 words, keeping 104352 word types\n",
      "04/22/2020 13:07:45 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #40000, processed 65298054 words, keeping 120787 word types\n",
      "04/22/2020 13:07:49 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #50000, processed 81702362 words, keeping 135390 word types\n",
      "04/22/2020 13:07:50 - INFO - gensim.models.word2vec -   collected 139102 word types from a corpus of 86174168 raw words and 52721 sentences\n",
      "04/22/2020 13:07:50 - INFO - gensim.models.word2vec -   Loading a fresh vocabulary\n",
      "04/22/2020 13:07:53 - INFO - gensim.models.word2vec -   effective_min_count=2 retains 71072 unique words (51% of original 139102, drops 68030)\n",
      "04/22/2020 13:07:53 - INFO - gensim.models.word2vec -   effective_min_count=2 leaves 86106138 word corpus (99% of original 86174168, drops 68030)\n",
      "04/22/2020 13:07:54 - INFO - gensim.models.word2vec -   deleting the raw counts dictionary of 139102 items\n",
      "04/22/2020 13:07:54 - INFO - gensim.models.word2vec -   sample=0.001 downsamples 41 most-common words\n",
      "04/22/2020 13:07:54 - INFO - gensim.models.word2vec -   downsampling leaves estimated 65592402 word corpus (76.2% of prior 86106138)\n",
      "04/22/2020 13:07:54 - INFO - gensim.models.base_any2vec -   estimated required memory for 71072 words and 150 dimensions: 120822400 bytes\n",
      "04/22/2020 13:07:54 - INFO - gensim.models.word2vec -   resetting layer weights\n",
      "04/22/2020 13:08:08 - INFO - gensim.models.base_any2vec -   training model with 10 workers on 71072 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "04/22/2020 13:08:09 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 0.96% examples, 630356 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:10 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 2.12% examples, 686075 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:11 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 3.09% examples, 677617 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:12 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 4.26% examples, 694172 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:13 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 5.46% examples, 708492 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:14 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 6.39% examples, 690566 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:15 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 7.53% examples, 696330 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:16 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 8.69% examples, 702769 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:17 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 9.67% examples, 694868 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:08:18 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 10.82% examples, 699269 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:19 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 11.95% examples, 702246 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:20 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 12.95% examples, 695620 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:21 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 14.15% examples, 700761 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:22 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 15.32% examples, 703260 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:23 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 16.45% examples, 704463 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:24 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 17.67% examples, 707834 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:25 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 18.68% examples, 703833 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:08:26 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 19.75% examples, 703466 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:27 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 20.91% examples, 705686 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:28 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 22.01% examples, 705842 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:29 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 23.01% examples, 703225 words/s, in_qsize 20, out_qsize 4\n",
      "04/22/2020 13:08:30 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 24.14% examples, 703623 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:31 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 25.13% examples, 700787 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:32 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 26.31% examples, 703331 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:08:33 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 27.38% examples, 704212 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:08:34 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 28.44% examples, 702835 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:35 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 29.63% examples, 705716 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:36 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 30.62% examples, 703238 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:37 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 31.66% examples, 701796 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:38 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 32.91% examples, 704925 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:39 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 33.91% examples, 703440 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:40 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 35.07% examples, 704344 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:41 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 36.26% examples, 706679 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:42 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 37.23% examples, 704051 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:43 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 38.41% examples, 705703 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:44 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 39.59% examples, 707376 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:45 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 40.61% examples, 705625 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:46 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 41.87% examples, 708016 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:47 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 42.94% examples, 708289 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:08:48 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 43.95% examples, 707059 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:49 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 45.13% examples, 708596 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:50 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 46.18% examples, 708395 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:08:51 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 47.33% examples, 709360 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:52 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 48.51% examples, 710438 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:53 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 49.55% examples, 709468 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:54 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 50.57% examples, 708705 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:55 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 51.79% examples, 710143 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:56 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 52.84% examples, 709262 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:57 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 53.95% examples, 709610 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:08:58 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 55.16% examples, 711003 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:08:59 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 56.09% examples, 708722 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:00 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 57.28% examples, 709829 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:01 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 58.52% examples, 711253 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:09:02 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 59.52% examples, 710082 words/s, in_qsize 19, out_qsize 2\n",
      "04/22/2020 13:09:03 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 60.75% examples, 711751 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:04 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 61.83% examples, 711810 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:05 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 62.77% examples, 710567 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:06 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 63.93% examples, 711766 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:07 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 65.03% examples, 712031 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:09:08 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 66.18% examples, 712215 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:09 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 67.36% examples, 713342 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:10 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 68.37% examples, 712245 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:11 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 69.53% examples, 712900 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:13 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 70.69% examples, 713899 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:14 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 71.72% examples, 712948 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:15 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 72.86% examples, 713431 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:16 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 73.98% examples, 713760 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:17 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 74.93% examples, 712249 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:18 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 76.10% examples, 712984 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:19 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 77.24% examples, 713235 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:09:20 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 78.32% examples, 712658 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:21 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 79.57% examples, 714050 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:22 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 80.63% examples, 713966 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:09:23 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 81.61% examples, 712769 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:09:24 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 82.76% examples, 713441 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:09:25 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 83.82% examples, 713045 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:26 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 84.83% examples, 712473 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:27 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 86.06% examples, 713344 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:09:28 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 87.06% examples, 712464 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:29 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 88.22% examples, 713285 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:09:30 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 89.41% examples, 714040 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:31 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 90.47% examples, 713857 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:32 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 91.68% examples, 714577 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:33 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 92.86% examples, 715321 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:34 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 93.88% examples, 714460 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:35 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 95.10% examples, 715501 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:09:36 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 96.28% examples, 716017 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:09:37 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 97.23% examples, 715024 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:38 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 98.41% examples, 715722 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 99.51% examples, 715628 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "04/22/2020 13:09:39 - INFO - gensim.models.base_any2vec -   EPOCH - 1 : training on 86174168 raw words (65595688 effective words) took 91.7s, 715678 effective words/s\n",
      "04/22/2020 13:09:40 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 1.10% examples, 712139 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:09:41 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 2.33% examples, 752910 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:42 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 3.35% examples, 727905 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:43 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 4.54% examples, 735124 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:44 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 5.69% examples, 740518 words/s, in_qsize 19, out_qsize 3\n",
      "04/22/2020 13:09:45 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 6.72% examples, 727391 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:46 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 7.91% examples, 736331 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:09:47 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 9.16% examples, 743677 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:48 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 10.16% examples, 735094 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:49 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 11.33% examples, 735490 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:09:50 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 12.42% examples, 731866 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:51 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 13.64% examples, 734087 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:52 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 14.84% examples, 736331 words/s, in_qsize 19, out_qsize 1\n",
      "04/22/2020 13:09:53 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 15.92% examples, 734113 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:54 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 17.20% examples, 739089 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:09:55 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 18.39% examples, 739472 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:09:56 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 19.40% examples, 735083 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:57 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 20.60% examples, 737220 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:58 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 21.78% examples, 738529 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:09:59 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 22.77% examples, 732923 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:10:01 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 23.91% examples, 733019 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:02 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 25.04% examples, 732551 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:03 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 26.09% examples, 730149 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:10:04 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 27.23% examples, 731745 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:10:05 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 28.33% examples, 731683 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:06 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 29.37% examples, 729696 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:07 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 30.52% examples, 730473 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:08 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 31.52% examples, 727885 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:10:09 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 32.72% examples, 728827 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:10:10 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 33.91% examples, 730488 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:11 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 34.99% examples, 728726 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:12 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 36.11% examples, 728745 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:13 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 37.27% examples, 729286 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:14 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 38.30% examples, 726877 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:10:15 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 39.43% examples, 727693 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:16 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 40.67% examples, 729067 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:17 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 41.76% examples, 728118 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:18 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 42.89% examples, 729096 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:10:19 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 44.08% examples, 729767 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:10:20 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 45.04% examples, 727049 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:21 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 46.19% examples, 727666 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:10:22 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 47.36% examples, 728323 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:23 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 48.47% examples, 728395 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:24 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 49.59% examples, 728392 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:25 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 50.66% examples, 728167 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:10:26 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 51.77% examples, 727665 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:27 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 53.03% examples, 729443 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:28 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 53.90% examples, 725975 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:10:29 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 54.66% examples, 721076 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:10:30 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 55.45% examples, 716318 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:10:31 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 56.08% examples, 710338 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:10:32 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 57.00% examples, 708350 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:10:33 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 57.75% examples, 704213 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:34 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 58.52% examples, 700119 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:35 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 59.53% examples, 699286 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:10:36 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 60.50% examples, 697686 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:10:37 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 61.41% examples, 696108 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:38 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 62.35% examples, 695124 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:39 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 63.24% examples, 693231 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:10:40 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 64.19% examples, 692018 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:41 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 65.18% examples, 691401 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:42 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 66.11% examples, 689269 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:43 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 67.01% examples, 687950 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:44 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 67.94% examples, 686451 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:45 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 68.75% examples, 684398 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:46 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 69.78% examples, 684003 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:10:47 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 70.75% examples, 683384 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:48 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 71.66% examples, 681985 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:10:49 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 72.57% examples, 680632 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:50 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 73.50% examples, 679484 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:51 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 74.28% examples, 677092 words/s, in_qsize 14, out_qsize 5\n",
      "04/22/2020 13:10:52 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 75.25% examples, 676250 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:53 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 76.13% examples, 674912 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:54 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 77.08% examples, 674099 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:10:55 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 78.09% examples, 673769 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:10:56 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 78.92% examples, 671655 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:57 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 79.73% examples, 669452 words/s, in_qsize 15, out_qsize 5\n",
      "04/22/2020 13:10:58 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 80.75% examples, 669600 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:10:59 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 81.51% examples, 667432 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:11:00 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 82.49% examples, 667277 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:11:01 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 83.42% examples, 666520 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:02 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 84.19% examples, 664522 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:03 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 85.23% examples, 664497 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:11:04 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 86.12% examples, 663440 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:11:05 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 86.89% examples, 661620 words/s, in_qsize 19, out_qsize 3\n",
      "04/22/2020 13:11:06 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 87.90% examples, 661269 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:07 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 88.87% examples, 661107 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:08 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 89.86% examples, 660800 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:10 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 90.87% examples, 660682 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:11:11 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 91.65% examples, 658844 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:12 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 92.56% examples, 658104 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:11:13 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 93.62% examples, 658297 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:14 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 94.43% examples, 657006 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:15 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 95.35% examples, 656304 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:11:16 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 96.37% examples, 656321 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:17 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 97.19% examples, 655196 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:18 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 98.14% examples, 654901 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:19 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 99.17% examples, 655138 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 99.97% examples, 653859 words/s, in_qsize 2, out_qsize 3\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "04/22/2020 13:11:20 - INFO - gensim.models.base_any2vec -   EPOCH - 2 : training on 86174168 raw words (65588424 effective words) took 100.3s, 653964 effective words/s\n",
      "04/22/2020 13:11:21 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 0.92% examples, 595448 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:22 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 1.81% examples, 583289 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:11:23 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 2.56% examples, 557495 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:24 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 3.60% examples, 587813 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:25 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 4.55% examples, 590358 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:26 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 5.33% examples, 576907 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:27 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 6.24% examples, 581107 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:11:28 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 7.17% examples, 579480 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:29 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 8.04% examples, 577361 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:30 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 9.02% examples, 580439 words/s, in_qsize 18, out_qsize 2\n",
      "04/22/2020 13:11:31 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 9.80% examples, 572896 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:32 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 10.70% examples, 573010 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:33 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 11.68% examples, 578848 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:34 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 12.47% examples, 573332 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:35 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 13.46% examples, 576379 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:36 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 14.44% examples, 579593 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:37 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 15.31% examples, 578335 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:11:38 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 16.25% examples, 580038 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:11:39 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 17.25% examples, 582389 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:11:40 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 18.10% examples, 579512 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:41 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 19.09% examples, 582914 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:11:42 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 19.99% examples, 581690 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:11:43 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 21.05% examples, 586007 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:44 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 22.11% examples, 589945 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:11:45 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 23.13% examples, 592584 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:46 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 24.24% examples, 597051 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:47 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 25.49% examples, 604087 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:11:48 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 26.59% examples, 608093 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:49 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 27.74% examples, 613692 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:11:50 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 28.84% examples, 617845 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:11:51 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 29.80% examples, 617631 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:52 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 30.97% examples, 621091 words/s, in_qsize 19, out_qsize 5\n",
      "04/22/2020 13:11:53 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 32.21% examples, 626870 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:11:54 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 33.42% examples, 630696 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:11:55 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 34.55% examples, 633431 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:56 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 35.65% examples, 635617 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:11:57 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 36.65% examples, 636128 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:11:58 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 37.86% examples, 639949 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:11:59 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 38.94% examples, 641871 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:00 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 40.10% examples, 644726 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:01 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 41.29% examples, 646836 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:12:02 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 42.28% examples, 646918 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:12:03 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 43.40% examples, 649196 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:04 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 44.63% examples, 652852 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:05 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 45.60% examples, 652408 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:06 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 46.67% examples, 653576 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:07 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 47.88% examples, 656220 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:08 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 48.90% examples, 656540 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:09 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 50.08% examples, 658764 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:10 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 51.28% examples, 660781 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:12:11 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 52.30% examples, 660667 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:12 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 53.39% examples, 661635 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:12:13 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 54.56% examples, 663600 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:12:14 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 55.62% examples, 663919 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:15 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 56.85% examples, 666460 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:16 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 57.94% examples, 667143 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:17 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 59.09% examples, 668398 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:18 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 60.23% examples, 669663 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:12:19 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 61.27% examples, 670153 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:20 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 62.41% examples, 671657 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:12:21 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 63.60% examples, 673509 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:22 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 64.51% examples, 672240 words/s, in_qsize 12, out_qsize 7\n",
      "04/22/2020 13:12:23 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 65.66% examples, 673430 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:24 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 66.92% examples, 675608 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:12:25 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 67.93% examples, 675055 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:12:26 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 69.20% examples, 677562 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:12:27 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 70.31% examples, 678556 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:28 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 71.25% examples, 677764 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:29 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 72.50% examples, 679649 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:30 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 73.58% examples, 680039 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:32 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 74.77% examples, 681200 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:33 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 75.96% examples, 682473 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:34 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 76.97% examples, 682041 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:35 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 77.93% examples, 681171 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:36 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 79.08% examples, 682233 words/s, in_qsize 20, out_qsize 6\n",
      "04/22/2020 13:12:37 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 80.11% examples, 682103 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:38 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 81.25% examples, 682761 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:12:39 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 82.42% examples, 684164 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:40 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 83.51% examples, 684408 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:41 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 84.67% examples, 685565 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:42 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 85.89% examples, 686225 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:12:43 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 86.86% examples, 685493 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:12:44 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 88.10% examples, 687069 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:45 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 89.21% examples, 687673 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:46 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 90.30% examples, 687923 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:12:47 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 91.53% examples, 689037 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:48 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 92.62% examples, 689162 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:49 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 93.75% examples, 689535 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:50 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 94.87% examples, 690006 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:12:51 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 95.87% examples, 689789 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:12:52 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 96.93% examples, 689699 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:53 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 98.11% examples, 690594 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:54 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 99.07% examples, 689755 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "04/22/2020 13:12:55 - INFO - gensim.models.base_any2vec -   EPOCH - 3 : training on 86174168 raw words (65595149 effective words) took 95.0s, 690511 effective words/s\n",
      "04/22/2020 13:12:56 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 1.12% examples, 725879 words/s, in_qsize 19, out_qsize 2\n",
      "04/22/2020 13:12:57 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 2.10% examples, 682938 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:12:58 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 3.20% examples, 701464 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:12:59 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 4.37% examples, 712664 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:13:00 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 5.42% examples, 704883 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:01 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 6.58% examples, 713858 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:02 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 7.73% examples, 720142 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:03 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 8.71% examples, 708357 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:13:04 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 9.87% examples, 713444 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:05 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 11.02% examples, 715740 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:13:06 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 11.72% examples, 691697 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:13:07 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 12.48% examples, 674625 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:13:08 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 13.21% examples, 657185 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:09 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 13.95% examples, 644320 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:10 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 14.92% examples, 643129 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:13:11 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 15.74% examples, 636598 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:12 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 16.73% examples, 635128 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:13 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 17.69% examples, 634008 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:14 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 18.59% examples, 629818 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:15 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 19.53% examples, 629350 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:16 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 20.53% examples, 630314 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:17 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 21.29% examples, 622708 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:18 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 22.30% examples, 622762 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:19 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 23.21% examples, 620956 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:20 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 24.04% examples, 617201 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:21 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 25.06% examples, 618564 words/s, in_qsize 15, out_qsize 0\n",
      "04/22/2020 13:13:22 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 25.91% examples, 615924 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:23 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 26.77% examples, 613513 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:24 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 27.76% examples, 615002 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:13:25 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 28.74% examples, 615949 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:26 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 29.55% examples, 613347 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:27 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 30.53% examples, 613979 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:28 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 31.61% examples, 616905 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:29 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 32.49% examples, 615445 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:13:30 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 33.48% examples, 615822 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:31 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 34.28% examples, 613035 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:13:32 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 35.21% examples, 612305 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:33 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 36.19% examples, 613213 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:34 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 36.91% examples, 609391 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:35 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 37.72% examples, 606985 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:36 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 38.56% examples, 605854 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:37 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 39.31% examples, 603299 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:38 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 40.35% examples, 604497 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:39 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 41.29% examples, 603948 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:40 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 42.15% examples, 602925 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:41 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 43.15% examples, 604174 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:42 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 44.11% examples, 605012 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:43 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 44.93% examples, 603605 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:44 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 45.86% examples, 603587 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:45 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 46.78% examples, 603789 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:13:46 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 47.70% examples, 603305 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:47 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 48.68% examples, 604091 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:48 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 49.57% examples, 603344 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:49 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 50.36% examples, 602108 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:50 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 51.32% examples, 602270 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:51 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 52.21% examples, 601276 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:52 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 53.21% examples, 602108 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:13:53 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 54.28% examples, 603659 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:54 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 55.13% examples, 602814 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:55 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 56.12% examples, 603181 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:56 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 57.07% examples, 603549 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:57 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 57.89% examples, 602484 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:58 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 58.84% examples, 602449 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:13:59 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 59.89% examples, 603653 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:14:00 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 60.73% examples, 602776 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:14:01 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 61.67% examples, 603165 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:02 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 62.56% examples, 603274 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:03 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 63.44% examples, 603175 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:14:04 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 64.45% examples, 604101 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:14:05 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 65.31% examples, 603563 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:06 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 66.13% examples, 602328 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:07 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 67.06% examples, 602444 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:14:08 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 67.97% examples, 602259 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:14:09 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 68.88% examples, 602435 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:14:11 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 69.88% examples, 602791 words/s, in_qsize 20, out_qsize 3\n",
      "04/22/2020 13:14:12 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 70.59% examples, 601163 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:13 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 71.61% examples, 601800 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:14 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 72.49% examples, 601281 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:15 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 73.39% examples, 600922 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:14:16 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 74.40% examples, 601607 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:17 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 75.32% examples, 601590 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:14:18 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 76.08% examples, 600204 words/s, in_qsize 19, out_qsize 1\n",
      "04/22/2020 13:14:19 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 77.12% examples, 601065 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:20 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 78.06% examples, 600963 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:21 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 78.87% examples, 600159 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:14:22 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 79.91% examples, 601224 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:23 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 80.76% examples, 600569 words/s, in_qsize 18, out_qsize 2\n",
      "04/22/2020 13:14:24 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 81.68% examples, 600561 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:14:25 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 82.60% examples, 600832 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:14:26 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 83.48% examples, 600545 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:27 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 84.39% examples, 600504 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:28 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 85.39% examples, 601014 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:29 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 86.26% examples, 600603 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:30 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 87.09% examples, 599470 words/s, in_qsize 14, out_qsize 5\n",
      "04/22/2020 13:14:31 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 88.17% examples, 600787 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:32 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 88.88% examples, 599329 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:14:33 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 89.81% examples, 599395 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:14:34 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 90.75% examples, 599667 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:35 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 91.58% examples, 598895 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:36 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 92.52% examples, 598872 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:14:37 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 93.48% examples, 598995 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:38 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 94.33% examples, 598578 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:14:39 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 95.42% examples, 599660 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:40 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 96.26% examples, 599120 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:41 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 97.05% examples, 598297 words/s, in_qsize 19, out_qsize 8\n",
      "04/22/2020 13:14:42 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 98.11% examples, 599105 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:14:43 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 98.97% examples, 598760 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 99.93% examples, 598951 words/s, in_qsize 7, out_qsize 1\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "04/22/2020 13:14:44 - INFO - gensim.models.base_any2vec -   EPOCH - 4 : training on 86174168 raw words (65594297 effective words) took 109.5s, 599093 effective words/s\n",
      "04/22/2020 13:14:45 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 0.88% examples, 587974 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:14:46 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 1.77% examples, 574036 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:14:47 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 2.66% examples, 582512 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:48 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 3.60% examples, 585463 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:49 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 4.47% examples, 578751 words/s, in_qsize 18, out_qsize 3\n",
      "04/22/2020 13:14:50 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 5.45% examples, 586673 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:14:51 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 6.38% examples, 590706 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:52 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 7.25% examples, 582650 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:14:53 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 8.18% examples, 584921 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:14:54 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 9.20% examples, 590260 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:14:55 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 10.11% examples, 591614 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:14:56 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 11.13% examples, 595477 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:14:57 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 12.01% examples, 593358 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:14:58 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 13.00% examples, 593975 words/s, in_qsize 19, out_qsize 1\n",
      "04/22/2020 13:14:59 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 13.98% examples, 596224 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:00 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 14.97% examples, 598542 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:01 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 15.96% examples, 601068 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:02 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 17.11% examples, 607950 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:03 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 18.16% examples, 610265 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:04 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 19.38% examples, 619225 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:05 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 20.56% examples, 626048 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:06 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 21.48% examples, 625150 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:07 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 22.70% examples, 631802 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:08 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 23.81% examples, 635540 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:09 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 24.77% examples, 634296 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:15:10 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 25.97% examples, 640108 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:11 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 27.06% examples, 643211 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:13 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 28.08% examples, 644384 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:14 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 29.25% examples, 648978 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:15 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 30.31% examples, 650211 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:15:16 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 31.38% examples, 651593 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:17 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 32.58% examples, 655345 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:18 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 33.69% examples, 656969 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:19 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 34.92% examples, 660583 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:20 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 36.14% examples, 664518 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:15:21 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 37.14% examples, 663977 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:22 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 38.24% examples, 665411 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:23 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 39.43% examples, 668226 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:24 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 40.52% examples, 668775 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:25 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 41.75% examples, 671616 words/s, in_qsize 19, out_qsize 1\n",
      "04/22/2020 13:15:26 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 42.98% examples, 674336 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:27 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 43.86% examples, 671901 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:28 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 45.04% examples, 674525 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:29 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 46.14% examples, 675764 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:30 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 47.13% examples, 675049 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:31 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 48.35% examples, 677537 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:15:32 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 49.46% examples, 678647 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:15:33 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 50.41% examples, 677846 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:34 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 51.65% examples, 680090 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:35 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 52.71% examples, 679069 words/s, in_qsize 15, out_qsize 4\n",
      "04/22/2020 13:15:36 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 53.91% examples, 681382 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:37 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 55.15% examples, 683463 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:38 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 56.13% examples, 682195 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:39 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 57.23% examples, 682977 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:40 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 58.46% examples, 684839 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:41 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 59.42% examples, 683803 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:42 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 60.58% examples, 685097 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:15:43 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 61.72% examples, 686443 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:44 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 62.54% examples, 684390 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:15:45 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 63.69% examples, 685784 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:46 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 64.85% examples, 687112 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:15:47 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 65.91% examples, 687125 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:48 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 66.95% examples, 686697 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:49 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 67.78% examples, 683946 words/s, in_qsize 19, out_qsize 1\n",
      "04/22/2020 13:15:50 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 68.40% examples, 679720 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:51 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 69.22% examples, 677598 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:15:52 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 69.88% examples, 673907 words/s, in_qsize 20, out_qsize 1\n",
      "04/22/2020 13:15:53 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 70.50% examples, 670231 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:54 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 71.19% examples, 667202 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:15:55 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 72.06% examples, 665461 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:15:56 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 72.72% examples, 662447 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:57 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 73.51% examples, 660509 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:58 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 74.33% examples, 658630 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:15:59 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 75.16% examples, 656998 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:16:00 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 76.07% examples, 656184 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:16:01 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 76.86% examples, 653788 words/s, in_qsize 20, out_qsize 2\n",
      "04/22/2020 13:16:02 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 77.69% examples, 652129 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:03 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 78.51% examples, 650809 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:04 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 79.30% examples, 648897 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:05 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 80.13% examples, 647706 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:06 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 81.32% examples, 649130 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:07 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 82.14% examples, 647968 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:08 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 83.33% examples, 649528 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:16:09 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 84.48% examples, 650762 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:16:10 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 85.49% examples, 650651 words/s, in_qsize 20, out_qsize 0\n",
      "04/22/2020 13:16:11 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 86.68% examples, 652287 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:12 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 87.78% examples, 652854 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:16:13 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 88.81% examples, 653140 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:14 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 90.05% examples, 654686 words/s, in_qsize 17, out_qsize 2\n",
      "04/22/2020 13:16:15 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 91.16% examples, 655318 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:16 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 92.32% examples, 656305 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:17 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 93.53% examples, 657697 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:16:18 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 94.51% examples, 657427 words/s, in_qsize 16, out_qsize 3\n",
      "04/22/2020 13:16:19 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 95.71% examples, 658813 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:20 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 96.90% examples, 659977 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:21 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 97.94% examples, 660064 words/s, in_qsize 19, out_qsize 0\n",
      "04/22/2020 13:16:22 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 98.98% examples, 660345 words/s, in_qsize 18, out_qsize 1\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   EPOCH - 5 : training on 86174168 raw words (65594972 effective words) took 99.2s, 661211 effective words/s\n",
      "04/22/2020 13:16:23 - INFO - gensim.models.base_any2vec -   training on a 430870840 raw words (327968530 effective words) took 495.7s, 661655 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    documents,\n",
    "    size=150,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=10,\n",
    "    iter=5)\n",
    "    \n",
    "#odel = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tobacco', 0.730054497718811),\n",
       " ('tob', 0.6298959255218506),\n",
       " ('tobacoo', 0.6190227270126343),\n",
       " ('smokes', 0.6182222366333008),\n",
       " ('smoke', 0.6151465177536011),\n",
       " ('cigar', 0.6050142049789429),\n",
       " ('cigars', 0.6028656363487244),\n",
       " ('smoker', 0.5915770530700684),\n",
       " ('ivda', 0.5884487628936768),\n",
       " ('pipe', 0.5807419419288635)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['smoking'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['medicine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Bio Sent2Vec - Not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sent2vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"/notebooks/storage/Downloads/transfer_model/BioSentVec_PubMed_MIMICIII-bigram_d700.bin\"\n",
    "model = sent2vec.Sent2vecModel()\n",
    "try:\n",
    "    model.load_model(model_path)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print('model successfully loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_sentence(text):\n",
    "    text = text.replace('/', ' / ')\n",
    "    text = text.replace('.-', ' .- ')\n",
    "    text = text.replace('.', ' . ')\n",
    "    text = text.replace('\\'', ' \\' ')\n",
    "    text = text.lower()\n",
    "\n",
    "    tokens = [token for token in word_tokenize(text) if token not in punctuation and token not in stop_words]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence = preprocess_sentence('Breast cancers with HER2 amplification have a higher risk of CNS metastasis and poorer prognosis.')\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vector = model.embed_sentence(sentence)\n",
    "print(sentence_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification, BertModel, BertTokenizer\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of splitting the data\n",
    "\n",
    "split = np.random.choice(\n",
    "    [\"train\", \"val\", \"test\"],\n",
    "    size=full_df.shape[0],\n",
    "    p=[.7, .15, .15]\n",
    ")\n",
    "full_df[\"split\"] = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = full_df.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sample_df[sample_df[\"split\"] == \"train\"]['TEXT']\n",
    "y_train = mlb.fit_transform(sample_df.ICD9_GRP_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/22/2020 12:20:45 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
      "04/22/2020 12:20:45 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "04/22/2020 12:20:45 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained('bert-base-uncased') \n",
    "\n",
    "bert_tok = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel(config)\n",
    "\n",
    "bert_transformer = BertTransformer(bert_tok, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6a312a149e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     ]\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Projects/MIMIC-III/src/bert_sklearn_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Projects/MIMIC-III/src/bert_sklearn_transformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Projects/MIMIC-III/src/bert_sklearn_transformer.py\u001b[0m in \u001b[0;36m_tokenize_and_predict\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         )\n\u001b[1;32m    792\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             )\n\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     ):\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add self attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    312\u001b[0m     ):\n\u001b[1;32m    313\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = MultinomialNB(fit_prior=True, class_prior = None)\n",
    "classifier = LogisticRegression(solver='sag')\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", bert_transformer),\n",
    "        (\"classifier\", OneVsRestClassifier(classifier)),\n",
    "    ]\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.LinearSVC(C=1.0, class_weight=\"balanced\")\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", bert_transformer),\n",
    "        (\"classifier\", classifier),\n",
    "    ]\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import (\n",
    "   CountVectorizer, TfidfTransformer\n",
    ")\n",
    "\n",
    "tf_idf = Pipeline([\n",
    "    (\"vect\", CountVectorizer()),\n",
    "    (\"tfidf\", TfidfTransformer())\n",
    "    ])\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=[\n",
    "        (\"bert\", bert_transformer),\n",
    "        (\"tf_idf\", tf_idf)\n",
    "        ])),\n",
    "        (\"classifier\", classifier),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working \n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# mlb = MultiLabelBinarizer()\n",
    "\n",
    "# X_train = sample_df['TEXT']\n",
    "# y_train = mlb.fit_transform(sample_df.ICD9_GRP_LIST)\n",
    "# model = BertClassifier(max_seq_length=128, train_batch_size=4)\n",
    "# model_gradient_accumulation_steps = 4\n",
    "\n",
    "# model\n",
    "# model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
